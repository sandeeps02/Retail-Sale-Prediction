{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeeps02/Retail-Sale-Prediction/blob/main/Retail_Sales_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - Retail Sales Prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Regression Analysis\n",
        "##### **Contribution**    - Individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "This project aimed to develop a predictive model for forecasting sales at Rossman stores using linear regression and regularization techniques. The dataset provided detailed information about store characteristics, promotional activities, holidays, and historical sales data.\n",
        "\n",
        "The data exploration phase revealed important insights such as higher sales on weekends and the impact of promotions and holidays on sales. The relationship between competition distance and sales was also explored, indicating a potential influence of convenience and customer preference for clustered shopping areas.\n",
        "\n",
        "The predictive model was built using linear regression and regularization techniques, specifically Lasso and Ridge regression. These techniques addressed issues such as overfitting and multicollinearity. The models were evaluated using metrics such as mean squared error, root mean squared error, mean absolute error, and R-squared score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "https://github.com/sandeeps02/Retail-Sale-Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "Rossmann, a leading European drug store chain, needs an accurate sales forecasting model to predict daily sales for its 3,000+ stores across seven countries. The current approach of relying on individual store managers predictions leads to inconsistent and varied accuracy. The business problem is to develop a robust sales forecasting model that minimizes errors and provides reliable estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import scipy.stats as stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrzGZriMWpow"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "rossman_store=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Rossmann Stores Data.csv\")\n",
        "store=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/store (1).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "rossman_store.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxh6c7Ruwb1"
      },
      "outputs": [],
      "source": [
        "rossman_store.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVMKR_QQbCLg"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "store.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxEeqExSu2_o"
      },
      "outputs": [],
      "source": [
        "store.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows_and_columns=rossman_store.shape\n",
        "print(f\"There are {rows_and_columns[0]} Rows and {rows_and_columns[1]} Columns, in rossman_store dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE2B6wYwvtDL"
      },
      "outputs": [],
      "source": [
        "rows_and_columns_in_store=store.shape\n",
        "print(f\"There are {rows_and_columns_in_store[0]} Rows and {rows_and_columns_in_store[1]} Columns in Store dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "rossman_store.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKq6NWVHwQys"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "store.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "rossman_store[rossman_store.duplicated()].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1KhA5b2xEq9"
      },
      "outputs": [],
      "source": [
        "store[store.duplicated()].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "na_value_r=rossman_store.isna().sum()\n",
        "na_value_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB5VRVh0xutr"
      },
      "outputs": [],
      "source": [
        "na_value_s=store.isna().sum()\n",
        "na_value_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values of rossman_store dataset\n",
        "plt.figure(figsize=(8,6))\n",
        "msno.matrix(rossman_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmZfIP4xzAVi"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values of store dataset\n",
        "plt.figure(figsize=(8,6))\n",
        "msno.matrix(store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "There are 2 dataset, viz. rossman and store. Rossman datset have 1017209 Rows and 9 Columns and store datset have 1115 rows and 10 columns. There are 0 null values and 0 duplicated values in rossman and few null and 0 duplicated values in store dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "rossman_store.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlcvKTmCTJTd"
      },
      "outputs": [],
      "source": [
        "store.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "rossman_store.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgAKz8T0TiKV"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "store.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "**Store:** A unique identifier for each store.\n",
        "\n",
        "**DayOfWeek:** The day of the week (1-7, where 1 represents Sunday and 7 represents Saturday).\n",
        "\n",
        "**Date:** The date of the sales data.\n",
        "\n",
        "**Sales:** The amount of sales on a particular day for a specific store.\n",
        "\n",
        "**Customers:** The number of customers on a particular day for a specific store.\n",
        "\n",
        "**Open:** A binary variable indicating whether the store was open (1) or closed (0) on a particular day.\n",
        "\n",
        "**Promo:** A binary variable indicating whether a promotion was active (1) or not (0) on a particular day.\n",
        "\n",
        "**StateHoliday:** A categorical variable indicating if the day was a state holiday (a, b, c) or not (0).\n",
        "\n",
        "**SchoolHoliday:** A binary variable indicating if it was a school holiday (1) or not (0).\n",
        "\n",
        "**StoreType:** The type of store (categorical variable).\n",
        "\n",
        "**Assortment:** The assortment level of the store (categorical variable).\n",
        "\n",
        "**CompetitionDistance:** The distance to the nearest competitor store.\n",
        "\n",
        "**CompetitionOpenSinceMonth:** The month when the nearest competitor store opened.\n",
        "\n",
        "**CompetitionOpenSinceYear:** The year when the nearest competitor store opened.\n",
        "\n",
        "**Promo2:** A binary variable indicating whether the store is participating in a continuing promotion (1) or not (0).\n",
        "\n",
        "**Promo2SinceWeek:** The calendar week when the store started participating in Promo2.\n",
        "\n",
        "**Promo2SinceYear:** The year when the store started participating in Promo2.\n",
        "\n",
        "**PromoInterval:** The intervals at which Promo2 is started, indicating the consecutive months the promotion is active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable of rossman_store dataset.\n",
        "for var in rossman_store.columns:\n",
        "  unique_count=rossman_store[var].nunique()\n",
        "  print(f'{var}',unique_count)\n",
        "  if unique_count<=5:\n",
        "    print(f'uniques values in {var} are',rossman_store[var].unique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2rnVkpm-Lfu"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable of store dataset.\n",
        "for va in store.columns:\n",
        "  unique_count=store[va].nunique()\n",
        "  print(f'{va}',unique_count)\n",
        "  if unique_count<=5:\n",
        "    print(f'unique values in {va} are',store[va].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xCl4GbjcXzb"
      },
      "outputs": [],
      "source": [
        "# Filling null values in store dataset with mean,median or 0.\n",
        "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median(),inplace=True)\n",
        "store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mean(),inplace=True)\n",
        "store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwcmB9xyilpF"
      },
      "outputs": [],
      "source": [
        "store['Promo2SinceWeek'].fillna(0,inplace=True)\n",
        "store['Promo2SinceYear'].fillna(0,inplace=True)\n",
        "store['PromoInterval'].fillna(0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqlrwCsHNzC8"
      },
      "outputs": [],
      "source": [
        "rossman_store['StateHoliday']=rossman_store['StateHoliday'].replace(0,'0')\n",
        "rossman_store['StateHoliday'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhH-uTc_cXuz"
      },
      "outputs": [],
      "source": [
        "# Merging both the Dataset.\n",
        "final=pd.merge(rossman_store,store,on='Store',how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-w8FauocXh9"
      },
      "outputs": [],
      "source": [
        "final.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoBnYq051HDk"
      },
      "outputs": [],
      "source": [
        "final.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CEO1isK1QNq"
      },
      "outputs": [],
      "source": [
        "final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbLAXXQ29aYQ"
      },
      "outputs": [],
      "source": [
        "final['Date']=pd.to_datetime(final['Date'],format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwSjcQOG9aLl"
      },
      "outputs": [],
      "source": [
        "final['CompetitionDistance']=final['CompetitionDistance'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MX2SYuL9Z-f"
      },
      "outputs": [],
      "source": [
        "final['CompetitionOpenSinceMonth']=final['CompetitionOpenSinceMonth'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnUkuoMoBODx"
      },
      "outputs": [],
      "source": [
        "final['CompetitionOpenSinceYear']=final['CompetitionOpenSinceYear'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUcTvRURBNtZ"
      },
      "outputs": [],
      "source": [
        "final['Promo2SinceYear']=final['Promo2SinceWeek'].astype(int)\n",
        "final['Promo2SinceWeek']=final['Promo2SinceWeek'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C_PiDcZ314J"
      },
      "outputs": [],
      "source": [
        "final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpSBDWxV31mW"
      },
      "outputs": [],
      "source": [
        "df=final.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYuDzk8O-4pw"
      },
      "outputs": [],
      "source": [
        "dependent_var=df['Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6bxoZXB-4lu"
      },
      "outputs": [],
      "source": [
        "num_var=df.describe().drop('Sales',axis=1).columns\n",
        "num_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0rvlQXW-4hq"
      },
      "outputs": [],
      "source": [
        "cat_var=df.describe(include=['object']).columns\n",
        "cat_var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "I have merged both the dataset i.e. rossman and store into final and then made a copy of this dataset to df. Filled the null values with mean,mode,median and some with 0 as required. Converted the date column from dtype-object to datetime and some columns from float to int dtype.Finally the numerical and categorical columns are stored in the respective variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1\n",
        "#Q1.How does the total sales vary across different days of the week? Are there any specific days that consistently exhibit higher or lower sales?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "fig=plt.figure(figsize=(10,6))\n",
        "cal=df.groupby('DayOfWeek')['Sales'].mean()\n",
        "sns.lineplot(x=cal.index,y=cal.values,marker='o')\n",
        "plt.xlabel('DaysOfWeek')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Sales during days of week');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "The line plot is suitable for visualizing the trend or pattern of a continuous variable. It helps in understanding how average sales vary across different days of the week and if there are any noticeable patterns or trends.\n",
        "It allows for a quick visual analysis and helps in identifying any day-of-week patterns in sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "The average sales during DayOfWeek 1 (Sunday) and DayOfWeek 7 (Saturday) are the highest, indicating higher sales on weekends. DayOfWeek 6 (Friday) has the lowest average sales, suggesting lower sales on that day compared to the other days of the week. This information highlights the pattern of higher sales on weekends (Sunday and Saturday) and comparatively lower sales on weekdays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "The insights gained from the analysis, such as higher average sales on weekends and lower average sales on Fridays, can help create a positive business impact. By allocating resources and implementing targeted marketing strategies during weekends, businesses can capitalize on increased sales potential. However, failure to adapt to these patterns may result in missed revenue opportunities and potential negative growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2\n",
        "#Q2-How does the sales vary across different storetypes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "fig=plt.figure(figsize=(10,7))\n",
        "sns.countplot(x='StoreType',data=df)\n",
        "plt.xlabel('Storetype')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Sales by StoreType')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "The countplot is suitable for visualizing the frequency or count of categorical variables.The chart aims to show the distribution of different store types and the frequency of each store type in the dataset.\n",
        "The countplot is a suitable choice for this scenario as it effectively displays the count or frequency of categorical data, allowing for quick comparisons and insights into the distribution of store types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Storetype a has the largest count, indicating that it is the most common type of store in the dataset.\n",
        "Storetype d and c have relatively high counts, suggesting that they are also popular store types.\n",
        "Storetype b has the lowest count among the store types, indicating that it is the least common type of store in the dataset.\n",
        "The difference in counts between Storetype a and the other store types suggests that Storetype a may have a larger presence or market share compared to the other types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "Yes, the gained insights can help create a positive business impact. By understanding the distribution and popularity of different store types, businesses can tailor their strategies to capitalize on the strengths and opportunities associated with each store type.\n",
        "\n",
        "However, one potential insight that could lead to negative growth is if Storetype b has significantly lower sales compared to the other store types. This could indicate that Storetype b is less appealing to customers or facing challenges in attracting sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3\n",
        "#Q3-How does the average sales and customers vary when it is a stateholiday or schoolholiday?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 5))\n",
        "\n",
        "cal_ssh = df.groupby('StateHoliday')['Sales'].mean()\n",
        "sns.barplot(x=cal_ssh.index, y=cal_ssh.values, ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Sales on State Holiday')\n",
        "axes[0, 0].set_xlabel('State Holiday')\n",
        "axes[0, 0].set_ylabel('Sales')\n",
        "\n",
        "cal_csh = df.groupby('StateHoliday')['Customers'].mean()\n",
        "sns.barplot(x=cal_csh.index, y=cal_csh.values, ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Customers on State Holiday')\n",
        "axes[0, 1].set_xlabel('State Holiday')\n",
        "axes[0, 1].set_ylabel('Customers')\n",
        "\n",
        "cal_ssch = df.groupby('SchoolHoliday')['Sales'].mean()\n",
        "sns.barplot(x=cal_ssch.index, y=cal_ssch.values, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Sales on School Holiday')\n",
        "axes[1, 0].set_xlabel('School Holiday')\n",
        "axes[1, 0].set_ylabel('Sales')\n",
        "\n",
        "cal_csch = df.groupby('SchoolHoliday')['Customers'].mean()\n",
        "sns.barplot(x=cal_csch.index, y=cal_csch.values, ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Customers on School Holiday')\n",
        "axes[1, 1].set_xlabel('School Holiday')\n",
        "axes[1, 1].set_ylabel('Customers')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "By arranging the plots in a grid, it becomes easier to observe and compare the bar heights across different categories and variables. This layout helps in gaining insights into how sales and customer behavior vary during state holidays and school holidays.\n",
        "\n",
        "The choice of bar plots is appropriate for this scenario as they effectively display the mean or aggregated values of a continuous variable (sales/customers) for different categories (state holiday/school holiday). The bar plots enable easy visual comparison of the variable values and provide insights into any differences or patterns observed across the holiday categories.\n",
        "\n",
        "Overall, the combination of bar plots in a grid layout is suitable for this analysis, allowing for a comprehensive examination of sales and customer behavior during state holidays and school holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "Sales on State Holidays: The average sales on State Holidays are lower compared to non-State Holidays. This suggests that State Holidays have a negative impact on sales.\n",
        "\n",
        "Customers on State Holidays: The average number of customers on State Holidays is also lower compared to non-State Holidays. This indicates that State Holidays attract fewer customers to the stores.\n",
        "\n",
        "Sales on School Holidays: The average sales on School Holidays are higher compared to non-School Holidays. This implies that School Holidays have a positive impact on sales.\n",
        "\n",
        "Customers on School Holidays: The average number of customers on School Holidays is also higher compared to non-School Holidays. This further supports the notion that School Holidays lead to increased customer visits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "The insight that School Holidays lead to higher sales and customer engagement can have a positive impact on business growth. By leveraging these periods with targeted marketing strategies, businesses can attract more customers and increase sales.\n",
        "\n",
        "On the other hand, the insight that State Holidays result in lower sales and customer numbers may have a negative impact on business growth. Businesses should be aware of these slower days and adjust their operations and marketing efforts accordingly.\n",
        "\n",
        "Overall, understanding the impact of different types of holidays on sales and customer behavior allows businesses to optimize their strategies and resource allocation, leading to positive business outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4\n",
        "#Q4-How does the Sales and Customers vary due to Promo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "fig,(axis1,axis2)=plt.subplots(1,2,figsize=(10,5))\n",
        "sns.barplot(x='Promo',y='Sales',data=df,ax=axis1)\n",
        "axis1.title.set_text('Sales VS Promo')\n",
        "sns.barplot(x='Promo',y='Customers',data=df,ax=axis2)\n",
        "axis2.title.set_text('Promo VS Customers')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "The bar plots are suitable for comparing the mean or aggregated values of a continuous variable (sales/customers) across different categories (promo/non-promo).\n",
        "\n",
        "The choice of bar plots is appropriate for this scenario as they effectively display the mean values of the variables for each category of the \"Promo\" variable. The bar plots allow for a clear visual comparison of the variable values and provide insights into any differences or patterns observed between the promo and non-promo periods.\n",
        "\n",
        "Overall, the combination of horizontal bar plots is suitable for this analysis, allowing for a straightforward comparison of sales and customer behavior during promo and non-promo periods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "Sales tend to be higher on days when there is a promotion (Promo = 1) compared to days without a promotion (Promo = 0).\n",
        "The presence of a promotion also leads to an increase in the number of customers visiting the store.\n",
        "Promotional activities have a positive impact on both sales and customer engagement, indicating that promotions are effective in attracting customers and driving sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "The gained insights from the chart suggest that implementing promotions can help create a positive business impact. Promotions are associated with higher sales and increased customer engagement, indicating that they can drive business growth and attract more customers to the store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5\n",
        "#Q5-How does the Sales vary across different storetypes and assortments?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "var = df.groupby(['StoreType', 'Assortment'])['Sales'].mean().reset_index()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(var['Sales'], labels=var['StoreType'] + ' ' + var['Assortment'], autopct='%1.1f%%')\n",
        "plt.title('Sales Distribution by Store Type and Assortment')\n",
        "plt.axis('equal')\n",
        "plt.legend(loc='upper right',bbox_to_anchor=(1.1,1))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "The pie chart is selected to represent the distribution of sales across different combinations of store types and assortments.\n",
        "\n",
        "The pie chart allows for a visual representation of the proportion of sales contributed by each store type and assortment combination. Each combination is represented as a slice in the pie chart, with the size of the slice indicating the percentage of sales it contributes to the total. The labels on the slices provide information about the specific store type and assortment combination.\n",
        "\n",
        "The chart provides insights into the sales distribution among different store types and assortments, enabling the identification of any dominant or significant combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "The store type \"b\" with assortment \"c\" has the highest percentage of sales, indicating that this combination is the most successful in generating sales.\n",
        "\n",
        "Assortment \"a\" and \"c\" contributes to a significant portion of sales across all store types.\n",
        "\n",
        "Store types \"d\" and \"a\" with assortment \"a\" have the lowest percentage of sales, suggesting that this combination may be less preferred by customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Yes, the gained insights can help create a positive business impact by identifying successful combinations that contribute to higher sales. By focusing on these successful combinations, businesses can optimize their strategies and allocate resources accordingly to maximize their sales potential.\n",
        "\n",
        "On the other hand, insights revealing lower sales in certain combinations can serve as indicators of potential areas for improvement. By analyzing the factors contributing to these negative growth patterns, businesses can identify underlying issues and implement targeted solutions to address them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6\n",
        "#How does the Sales vary by CompetitionDistance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "sns.scatterplot(x='CompetitionDistance',y='Sales',data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "The scatter plot is selected to visualize the relationship between the competition distance and sales.\n",
        "\n",
        "A scatter plot is suitable for this scenario as it allows us to examine the distribution and correlation between two continuous variables, in this case, the competition distance and sales. Each data point represents a store, with the competition distance on the x-axis and the corresponding sales on the y-axis.\n",
        "\n",
        "By plotting the data points on a scatter plot, we can observe any patterns, trends, or outliers in the relationship between competition distance and sales. It helps in identifying whether there is a positive, negative, or no correlation between the two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "From the scatter plot, we can observe that there is no clear linear relationship between the competition distance and sales. The data points are scattered across the plot, indicating that the competition distance alone may not be a strong predictor of sales.\n",
        "\n",
        "However, we can still gain some insights from the visualization. We can see that there is a concentration of data points around lower competition distances, suggesting that stores located closer to their competitors tend to have higher sales. This could be attributed to factors such as convenience and customer preference for clustered shopping areas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "The insights gained from the scatter plot can potentially have a positive business impact by informing decisions related to store location and competition. However, there are no specific insights that directly indicate negative growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7\n",
        "#What is the relation between store oppenness and Sales?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='Open',y='Sales',data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "The bar plot is selected to visualize the relationship between the \"Open\" variable and sales.\n",
        "\n",
        "By using a bar plot, we can easily compare the average sales between open and closed stores. It helps in understanding whether the store being open or closed has an impact on sales. The height of each bar represents the average sales for the corresponding category, allowing for a clear visual comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "From the bar plot, we can observe that the sales are significantly higher when the store is open compared to when it is closed. This suggests that the store being open has a positive impact on sales.And also this clearly was to check foe the outlier detection. As sales when the store is closed is clearly an outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insight gained from the chart that shows higher sales when the store is open can help create a positive business impact. By ensuring that the store is open during peak sales periods and optimizing store hours, the business can maximize sales and revenue."
      ],
      "metadata": {
        "id": "hFLpeUzj6VQV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8\n",
        "#Checking the Distribution of the dependent variable i.e. Sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "sns.distplot(df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "The histogram is selected to visualize the distribution of the \"Sales\" variable.\n",
        "\n",
        "The x-axis represents the range of sales values, and the y-axis represents the frequency or count of occurrences.\n",
        "\n",
        "By using a histogram, we can observe the shape of the distribution, identify any patterns or clusters in the data, and get an idea of the central tendency and spread of the sales values. It helps in understanding the overall distribution of sales and detecting any outliers or unusual patterns.\n",
        "\n",
        "Additionally, the histogram can provide insights into the skewness or asymmetry of the sales distribution. Skewness can indicate whether the sales values are concentrated towards one end of the distribution or evenly distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "There are two peaks in the distribution which indicated that the data has two clusters.The first peak is concentrated at 0 that indicates a high number of shops were closed and had 0 sales.\n",
        "\n",
        "The sales data is positively skewed, with a longer right tail. This indicates that there are relatively few instances of high sales values, while most sales values are concentrated towards the lower end.\n",
        "\n",
        "The majority of sales fall within a certain range, as evidenced by the peak in the distribution. This suggests that there may be some common sales patterns or trends that influence the majority of the sales data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "The gained insights from the sales distribution can potentially help create a positive business impact. By understanding the distribution and characteristics of sales data, businesses can make informed decisions to optimize their strategies and drive growth. For example, identifying the presence of two clusters in the data allows businesses to differentiate between closed shops and open shops, enabling them to focus on improving sales for open shops and addressing the reasons behind closed shops.\n",
        "\n",
        "However, there is a potential insight that could lead to negative growth. The presence of a significant number of closed shops with zero sales indicates a potential issue or challenge that needs to be addressed. If a large portion of the stores consistently remain closed or have zero sales, it can negatively impact overall business performance. Therefore, it is important for businesses to investigate the reasons behind closed shops and take appropriate actions to minimize their occurrence and maximize sales opportunities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9\n",
        "#Checking the relation between numerical variables and dependent variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "for col in num_var:\n",
        "  fig=plt.figure(figsize=(10,5))\n",
        "  ax=fig.gca()\n",
        "  feature=df[col]\n",
        "  label=df['Sales']\n",
        "  correlation=feature.corr(label)\n",
        "  sns.scatterplot(x=feature,y=label)\n",
        "  z=np.polyfit(df[col],df['Sales'],1)\n",
        "  y_hat=np.poly1d(z)(df[col])\n",
        "  plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Sales')\n",
        "  ax.set_title(col+' '+'Sales'+' correlation:'+str(correlation))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "The specific chart chosen in this case, which is a scatter plot with a regression line, was likely selected to visualize the relationship between each numeric variable and the \"Sales\" variable. Scatter plots are commonly used to examine the correlation or association between two continuous variables. By plotting the numeric variable on the x-axis and the \"Sales\" variable on the y-axis, the chart allows for a visual exploration of their relationship.\n",
        "\n",
        "The regression line added to the scatter plot helps to estimate the linear relationship between the variables. It provides information about the direction (positive or negative) and the slope of the relationship. This can help identify whether there is a positive or negative correlation between the numeric variable and \"Sales\" and how strong the relationship might be.\n",
        "\n",
        "Additionally, including the correlation coefficient in the title of each subplot provides a quantitative measure of the strength and direction of the linear relationship. This helps in understanding the degree to which the numeric variable and \"Sales\" are associated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "From the scatter plots, we can observe the relationship between each numerical variable and the sales. Here are some insights that can be derived:\n",
        "\n",
        "Customers: There is a positive correlation between the number of customers and sales. As the number of customers increases, the sales also tend to increase. This suggests that attracting more customers can potentially lead to higher sales.\n",
        "\n",
        "CompetitionDistance: The correlation between competition distance and sales is relatively weak. The scatter plot does not show a clear linear relationship between these variables. However, there might be some non-linear or indirect relationships that need to be further explored.\n",
        "\n",
        "Promo: When there is a promotion (Promo=1), there tends to be higher sales compared to when there is no promotion (Promo=0). This indicates that promotional activities have a positive impact on sales.\n",
        "\n",
        "SchoolHoliday: The presence of a school holiday (SchoolHoliday=1) does not show a clear pattern in terms of its impact on sales. The scatter plot does not exhibit a significant correlation between these variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "The gained insights can potentially help create a positive business impact by providing valuable information about the relationships between different numerical variables and sales. These insights can guide businesses in making data-driven decisions to optimize their strategies and maximize sales. For example:\n",
        "\n",
        "The positive correlation between the number of customers and sales suggests that focusing on customer acquisition and retention strategies can lead to increased sales.\n",
        "\n",
        "The observation that promotions have a positive impact on sales indicates that businesses can leverage promotional activities to drive sales growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10\n",
        "#Analysis of categorical variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "for col in cat_var:\n",
        "  fig=plt.figure(figsize=(10,5))\n",
        "  counts=df[col].value_counts()\n",
        "  ax=fig.gca()\n",
        "  feature=df[col]\n",
        "  sns.barplot(x=counts.index, y=counts.values, ax=ax, color='cyan')\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Count')\n",
        "  ax.set_title(col + ' Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "The specific chart chosen in this case is a bar chart. The reason for choosing this chart is to visualize the count or frequency of different categories within each categorical variable. The bar chart provides a clear and concise representation of the distribution of categorical data, making it easy to compare the frequency of different categories.\n",
        "\n",
        "In summary, the bar chart is chosen to visually represent the count or frequency of categories within categorical variables, enabling us to gain insights into the distribution and relative importance of different categories for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "StateHoliday: The highest count is observed for StateHoliday \"0,\" indicating that the majority of days are not state holidays. Following that, the count decreases in the order of \"a\" type holiday, \"b\" type holiday, and \"c\" type holiday. This suggests that regular non-holiday days are the most common, while specific state holidays occur less frequently.\n",
        "\n",
        "PromoInterval: The highest count is observed for PromoInterval \"0,\" indicating that the majority of stores do not have a defined promotional interval. Among the stores with defined intervals, the months with the highest count are January, April, July, and October. This is followed by February, May, August, and November. The months with the least count are March, June, September, and December. This indicates that certain months are more favored for running promotions compared to others.\n",
        "\n",
        "StoreType: Store type \"a\" has the highest count, indicating that there are more stores of this type in the dataset. This is followed by store types \"d,\" \"c,\" and \"b.\" This suggests that store type \"a\" is the most prevalent, while store type \"b\" is the least common.\n",
        "\n",
        "Assortment: The highest count is observed for assortment type \"a,\" indicating that there are more stores offering this assortment type. This is followed by assortment type \"b\" and the least count is for assortment type \"c.\" This suggests that assortment type \"a\" is more widely adopted by the stores in the dataset, while assortment type \"c\" is the least preferred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "The gained insights can potentially help create a positive business impact by providing valuable information about customer behavior, store operations, and promotional strategies.\n",
        "\n",
        "Negative growth can occur if businesses fail to adapt to the insights or misinterpret them. For example:\n",
        "\n",
        "StateHoliday: If a business neglects the impact of state holidays and fails to adjust its operations or promotions accordingly, it may miss out on potential sales opportunities during those periods. This can lead to negative growth compared to competitors who effectively leverage state holidays for increased sales.\n",
        "\n",
        "PromoInterval: Failing to align promotional activities with the months of higher customer engagement (such as January, April, July, and October) may result in reduced effectiveness of promotions. Businesses should carefully plan and allocate resources to capitalize on these peak months to maximize sales potential.\n",
        "\n",
        "StoreType and Assortment: Businesses should analyze the customer preferences and market demand for different store types and assortment types. Neglecting the market demand or failing to offer the preferred store type or assortment type may result in lower customer satisfaction and negative growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11\n",
        "#Total Sales done by each Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "fig=plt.figure(figsize=(200,15))\n",
        "c=df.groupby('Store')['Sales'].sum()\n",
        "ax=sns.pointplot(x=c.index,y=c.values,color='r')\n",
        "plt.xticks(rotation=90);\n",
        "ax.set_ylim(bottom=0)\n",
        "ax.set_xlim(0)\n",
        "ax.vlines(c.index,1, c.values, linestyles='dashed', colors='gray', alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "The point plot allows us to plot the sales values for each store as individual points on the y-axis, with the corresponding store identifier (index) on the x-axis. This provides a clear representation of the total sales for each store, allowing for easy comparison and identification of stores with higher or lower sales.\n",
        "\n",
        "The point plot also includes dashed vertical lines connecting each point to the x-axis, providing a visual reference to easily track the sales values for each store. This helps in understanding the distribution of sales across different stores and identifying any significant variations or patterns.\n",
        "\n",
        "The large figure size (200,15) chosen for the plot ensures that the chart is displayed with an extended width, accommodating the potentially large number of store identifiers on the x-axis without overlapping or overcrowding. This enables better readability and interpretation of the sales distribution across stores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "From the visualization, it can be observed that store 262 has the highest sales among all the stores. This indicates that store 262 is performing exceptionally well in terms of generating sales compared to other stores in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "The gained insights, particularly the identification of store 262 as the top-performing store, can potentially help create a positive business impact. By analyzing the strategies and factors contributing to the success of store 262, other stores can learn from its best practices and implement similar strategies to improve their own sales performance. This benchmarking and targeted analysis can lead to positive growth by identifying effective approaches and implementing them across the business."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        " # Correlation Heatmap visualization code\n",
        "fig=plt.figure(figsize=(20,7))\n",
        "correlation=df.corr(numeric_only=True)\n",
        "sns.heatmap(abs(correlation),annot=True,cmap='magma')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "I picked the correlation heatmap chart because it is a useful visualization for understanding the relationships between numerical variables in the dataset. The heatmap allows us to quickly identify strong positive or negative correlations between variables. By using color-coded cells and annotations, it provides a clear and concise overview of the correlation values. This helps in identifying potential patterns or dependencies among variables, which can be valuable for making data-driven decisions and uncovering insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Sales and Customers: There is a strong positive correlation (0.89) between sales and the number of customers. This indicates that an increase in customer count is likely to result in higher sales.\n",
        "\n",
        "Day of the Week and Sales: There is a moderate positive correlation (0.46) between the day of the week and sales. This suggests that certain days of the week may have a greater impact on sales.\n",
        "\n",
        "Open and Sales: There is a strong positive correlation (0.68) between the opening status of the store and sales. This implies that when the store is open, sales tend to be higher.\n",
        "\n",
        "Promo and Sales: There is a moderate positive correlation (0.45) between promotional activities and sales. This suggests that running promotions can positively influence sales.\n",
        "\n",
        "Open and Customers: There is a strong positive correlation (0.62) between the opening status of the store and the number of customers. This indicates that when the store is open, there tends to be a higher number of customers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC5_Xs0UbndK"
      },
      "outputs": [],
      "source": [
        "# Checking Multicollinearty\n",
        "def cal_vif(X):\n",
        "  vif=pd.DataFrame()\n",
        "  vif['Variables']=X.columns\n",
        "  vif['vif']=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\n",
        "  return(vif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmEs67U7d-B_"
      },
      "outputs": [],
      "source": [
        "cal_vif(df[[i for i in df.describe().columns if i not in ['Sales','Promo2SinceYear','Promo2SinceWeek']]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2449yyrd9jz"
      },
      "outputs": [],
      "source": [
        "cal_vif(df[[i for i in df.describe().columns if i not in ['Sales','Promo2SinceYear','Promo2SinceWeek','CompetitionOpenSinceYear']]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSRa3GHJd9-Z"
      },
      "outputs": [],
      "source": [
        "numerical_features=['Store','DayOfWeek','Customers','Promo','SchoolHoliday','CompetitionDistance','CompetitionOpenSinceMonth','Open','Promo2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "**Statement-1:** The average sales of stores with a Promo are higher than the average sales of stores without a Promo.\n",
        "\n",
        "**Statement-2:** There is a significant difference in the average sales of stores across different store types.\n",
        "\n",
        "**Statement-3:** The average sales of stores during school holidays are higher than the average sales during non-school holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1\n",
        "#The average sales of stores with a Promo are higher than the average sales of stores without a Promo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Null Hypothesis (H0): The average sales of stores with a \"Promo\" are the same as the average sales of stores without a \"Promo.\"\n",
        "\n",
        "Alternative Hypothesis (H1): The average sales of stores with a \"Promo\" are higher than the average sales of stores without a \"Promo.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "sales_with_promo = df[df['Promo'] == 1]['Sales']\n",
        "sales_without_promo = df[df['Promo'] == 0]['Sales']\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(sales_with_promo, sales_without_promo, alternative='greater')\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    conclusion = \"Reject the null hypothesis. The average sales of stores with a 'Promo' are higher than the average sales without a 'Promo'.\"\n",
        "else:\n",
        "    conclusion = \"Fail to reject the null hypothesis. There is no significant difference in the average sales with and without a 'Promo'.\"\n",
        "print(conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Two-sampled t-test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq_KIWDcEPc1"
      },
      "source": [
        "#There is a significant difference in the average sales of stores across different store types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "Null Hypothesis(H0):There is no significant difference in the average sales of stores across different store types.\n",
        "\n",
        "Alternate Hypothesis(H1):There is a significant difference in the average sales of stores across different store types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "store_type_a = df[df['StoreType'] == 'a']['Sales']\n",
        "store_type_b = df[df['StoreType'] == 'b']['Sales']\n",
        "store_type_c = df[df['StoreType'] == 'c']['Sales']\n",
        "store_type_d = df[df['StoreType'] == 'd']['Sales']\n",
        "\n",
        "f_stat, p_value = stats.f_oneway(store_type_a, store_type_b, store_type_c, store_type_d)\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    conclusion = \"Reject the null hypothesis. There is a significant difference in the average sales across different store types.\"\n",
        "else:\n",
        "    conclusion = \"Fail to reject the null hypothesis. There is no significant difference in the average sales across different store types.\"\n",
        "print(conclusion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "ANOVA test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8XXa2DRFJdr"
      },
      "source": [
        "#The average sales of stores during school holidays are higher than the average sales during non-school holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "Null Hypothesis(H0):The average sales of stores during school holidays are the same as the average sales during non-school holidays.\n",
        "\n",
        "Alternate Hypothesis(H1):The average sales of stores during school holidays are higher than the average sales during non-school holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "sales_school_holidays = df[df['SchoolHoliday'] == 1]['Sales']\n",
        "sales_non_school_holidays = df[df['SchoolHoliday'] == 0]['Sales']\n",
        "t_stat, p_value = stats.ttest_ind(sales_school_holidays, sales_non_school_holidays, alternative='greater')\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    conclusion = \"Reject the null hypothesis. The average sales during school holidays are higher than the average sales during non-school holidays.\"\n",
        "else:\n",
        "    conclusion = \"Fail to reject the null hypothesis. There is no significant difference in the average sales during school holidays and non-school holidays.\"\n",
        "print(conclusion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "Two sampled t-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 1. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "# One Hot Encoding\n",
        "df=pd.get_dummies(df,columns=['StateHoliday','StoreType','Assortment','PromoInterval'],prefix=['StateHoliday','StoreType','Assortment','PromoInterval'])\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3djMJ5ugVedy"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "One-hot encoding was chosen in this case because it is suitable for categorical columns that do not have a natural order or hierarchy. By converting each category into a separate binary feature column, it allows for easy representation of categorical data in a machine learning model.\n",
        "\n",
        "By using one-hot encoding, we can effectively represent the categorical variables in a numerical format that can be used as input for various machine learning algorithms. It helps in avoiding the potential issue of assigning incorrect numerical values to categories, and ensures that the categorical information is properly captured in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiCge753VrDm"
      },
      "outputs": [],
      "source": [
        "# Removing all the rows when open==0 and sales==0,as these are the stores that are closed for Renovation.\n",
        "df = df.loc[~((df['Open'] == 0) & (df['Sales'] == 0))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "features=numerical_features.copy()\n",
        "features.extend(['StateHoliday_0', 'StateHoliday_a', 'StateHoliday_b',\n",
        "       'StateHoliday_c', 'StoreType_a', 'StoreType_b', 'StoreType_c',\n",
        "       'StoreType_d', 'Assortment_a', 'Assortment_b', 'Assortment_c',\n",
        "       'PromoInterval_0', 'PromoInterval_Feb,May,Aug,Nov',\n",
        "       'PromoInterval_Jan,Apr,Jul,Oct', 'PromoInterval_Mar,Jun,Sept,Dec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUe--hI0o6cf"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Checking distribution of dependent variable after removing outliers\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "sns.distplot(df['Sales'])\n",
        "df['Sales'].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzoDJJ7gXgk_"
      },
      "outputs": [],
      "source": [
        "# Applying Transformation\n",
        "Transformed=np.sqrt(df['Sales'])\n",
        "sns.distplot(Transformed)\n",
        "Transformed.skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ejUdEg4fXqT"
      },
      "outputs": [],
      "source": [
        "# Defining Dependent and independent variable\n",
        "X=df[features]\n",
        "Y=np.sqrt(df['Sales'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "scaler=StandardScaler()\n",
        "X=scaler.fit_transform(df[features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler is a commonly used method for scaling numerical data in machine learning tasks.\n",
        "\n",
        "StandardScaler works by transforming the data such that it has a mean of 0 and a standard deviation of 1. It achieves this by subtracting the mean and dividing by the standard deviation of the data.By scaling the data, we can prevent certain features from dominating the learning process or having undue influence based on their original scale."
      ],
      "metadata": {
        "id": "0XGg9VkwIhlI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "a data splitting ratio of 80:20 has been used, where 80% of the data is used for training (X_train and Y_train) and 20% is used for testing (X_test and Y_test).\n",
        "\n",
        "The choice of the data splitting ratio depends on various factors, including the size of the dataset, the complexity of the problem, and the availability of data. In this case, a ratio of 80:20 is commonly used and provides a good balance between having enough data for training the model and having a sufficient amount of data for testing and evaluating the model's performance.\n",
        "\n",
        "Using a larger portion of the data for training (80%) helps the model to learn patterns and relationships more effectively, which can lead to better performance and generalization. The remaining portion of the data (20%) is used for testing to assess how well the model performs on unseen data and to estimate its performance in real-world scenarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb5nx0kfno5l"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,X_train,Y_train,Y_test,Y_pred):\n",
        "\n",
        "  y_test = np.square(Y_test)\n",
        "  y_pred = np.square(Y_pred)\n",
        "  y_train = np.square(Y_train)\n",
        "  y_train_pred = np.square(model.predict(X_train))\n",
        "\n",
        "  #Evaluation metrics calculation\n",
        "  mse = mean_squared_error(y_test,y_pred)\n",
        "  mae = mean_absolute_error(y_test,y_pred)\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2_train = r2_score(y_train,y_train_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  r2_adjusted = 1 - (1 - r2) * ((len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1))\n",
        "\n",
        "  # Print evaluation metrics\n",
        "  print(\"MSE:\", mse)\n",
        "  print(\"RMSE:\", rmse)\n",
        "  print(\"MAE:\", mae)\n",
        "  print(\"Train R2:\", r2_train)\n",
        "  print(\"Test R2:\", r2)\n",
        "  print(\"Adjusted R2:\", r2_adjusted)\n",
        "\n",
        "  # Plot actual and predicted values\n",
        "  plt.figure(figsize=(18, 6))\n",
        "  plt.plot(y_pred[:100])\n",
        "  plt.plot(y_test[:100])\n",
        "  plt.legend([\"Predicted\", \"Actual\"])\n",
        "  plt.title('Actual and Predicted Sales', fontsize=18)\n",
        "\n",
        "  model_score = [mse, mae, rmse,r2_train,r2,r2_adjusted]\n",
        "  return model_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5pDs6JIp49y"
      },
      "outputs": [],
      "source": [
        "# Create a score dataframe\n",
        "score = pd.DataFrame(index = ['MSE', 'RMSE','MAE', 'Train R2', 'Test R2', 'Adjusted R2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "regressor=LinearRegression()\n",
        "# Fit the Algorithm\n",
        "regressor.fit(X_train,Y_train)\n",
        "# Predict on the model\n",
        "Y_pred=regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "linear_score = evaluate_model(regressor,X_train,Y_train,Y_test,Y_pred)\n",
        "# Evaluation Metric Score chart\n",
        "score['Linear regression'] = linear_score\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "regressor=LinearRegression()\n",
        "# Define the parameters to be optimized\n",
        "param_grid = {'fit_intercept': [True, False]}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
        "# Fit the algorithm\n",
        "grid_search.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf9RVlqDqL6M"
      },
      "outputs": [],
      "source": [
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best R2 score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1FQ-xH8qLrk"
      },
      "outputs": [],
      "source": [
        "# use the best parameter to train the model\n",
        "best_reg = grid_search.best_estimator_\n",
        "best_reg.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehs1UZPzqLei"
      },
      "outputs": [],
      "source": [
        "# predict on test data\n",
        "Y_pred2 = best_reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nyghd75ata3z"
      },
      "outputs": [],
      "source": [
        "linear_score2 = evaluate_model(best_reg,X_train,Y_train,Y_test,Y_pred2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osgzf7ykt6UQ"
      },
      "outputs": [],
      "source": [
        "score['Linear regression tuned'] = linear_score2\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "GridSearchCV is used for hyperparameter optimization. GridSearchCV is a popular technique for hyperparameter tuning that exhaustively searches over a specified parameter grid to find the best combination of hyperparameters for a given model.\n",
        "\n",
        "The reason for using GridSearchCV in this case could be to systematically explore the hyperparameter space of the LinearRegression model. By providing a parameter grid (param_grid), GridSearchCV will perform an exhaustive search over all possible combinations of hyperparameters specified in the grid. It evaluates each combination using cross-validation (cv=5) and selects the best combination based on the scoring metric (scoring='r2', in this case).\n",
        "\n",
        "GridSearchCV is a reliable technique that helps to fine-tune model performance by finding the best hyperparameter values. It provides a systematic and comprehensive approach to hyperparameter optimization and can be beneficial when there are a limited number of hyperparameters to tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "Based on the provided evaluation metric scores for Linear Regression and Linear Regression tuned models, there is no improvement in the performance of the model after hyperparameter tuning.\n",
        "\n",
        "Both models have identical scores for all evaluation metrics, including MSE, RMSE, MAE, Train R2, Test R2, and Adjusted R2. The scores remain the same before and after hyperparameter optimization.\n",
        "\n",
        "Therefore, in this specific case, the hyperparameter tuning using GridSearchCV did not result in any improvement in the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2DA6T7XuSvt"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation\n",
        "L1=Lasso()\n",
        "# Fit the Algorithm\n",
        "L1.fit(X_train,Y_train)\n",
        "# Predict on the model\n",
        "Y_pred_L1=L1.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "lasso_score=evaluate_model(L1,X_train,Y_train,Y_test,Y_pred_L1)\n",
        "score['Lasso regression'] = lasso_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "L1 = Lasso()\n",
        "# Defining Hyperparameters\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = RandomizedSearchCV(L1, parameters, scoring='r2', cv=5,return_train_score=True,n_iter=10)\n",
        "#fitting model\n",
        "lasso_regressor.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el-8qDdK1-gv"
      },
      "outputs": [],
      "source": [
        "#getting optimum parameters\n",
        "print(\"The optimum alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" r2 score is: \", lasso_regressor.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbqSUxtJ1-SV"
      },
      "outputs": [],
      "source": [
        "# Import the Lasso Regression class with best alpha\n",
        "L1 = Lasso(alpha = lasso_regressor.best_params_['alpha'])\n",
        "\n",
        "# Initialize an instance of the class\n",
        "L1.fit(X_train, Y_train)\n",
        "\n",
        "# Fit the lasso regression model to your training data\n",
        "Y_pred_L1cv = L1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wflgXGdx24lK"
      },
      "outputs": [],
      "source": [
        "#Evaluation matrices for Lasso regression\n",
        "lasso2 = evaluate_model(L1,X_train,Y_train,Y_test,Y_pred_L1cv)\n",
        "score['Lasso regression tuned'] = lasso2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmHFasXf7Wsk"
      },
      "outputs": [],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "I have used RandomizedSearchCV for hyperparameter optimization. RandomizedSearchCV is a technique that randomly samples a subset of hyperparameter combinations from the specified parameter grid and performs cross-validation to determine the best hyperparameters.\n",
        "\n",
        "I chose RandomizedSearchCV because it is more efficient than GridSearchCV when dealing with a large number of hyperparameters and a large dataset. It randomly selects a subset of hyperparameter combinations, reducing the computational cost while still providing a good chance of finding optimal or near-optimal hyperparameters.\n",
        "\n",
        "By using RandomizedSearchCV, we can explore a wide range of hyperparameter values and find the best combination that maximizes the R2 score, which is the evaluation metric used in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Based on the evaluation metric score chart, we can observe the following improvements:\n",
        "\n",
        "Lasso regression (untuned) shows slightly higher MSE, RMSE, and MAE compared to linear regression (tuned). This indicates that the linear regression model with tuned hyperparameters performs slightly better in terms of prediction accuracy.\n",
        "\n",
        "Lasso regression (tuned) shows a slightly lower Train R2 and Test R2 compared to linear regression (tuned). However, the difference is marginal, indicating that both models have similar predictive performance.\n",
        "\n",
        "The adjusted R2 scores for linear regression (tuned) and lasso regression (tuned) are also comparable, suggesting that both models explain a similar proportion of the variability in the target variable while considering the number of predictors.\n",
        "\n",
        "Overall, the improvements between linear regression (untuned) and linear regression (tuned) are relatively small, while the performance of lasso regression (tuned) is slightly lower than that of linear regression (tuned) in terms of MSE, RMSE, MAE, and R2 scores. However, the differences in performance are not substantial, and the choice between these models may depend on other factors such as interpretability and feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Evaluation metrics such as MSE, RMSE, MAE, and R2 provide indications of the accuracy and performance of a machine learning model. Lower values of MSE, RMSE, and MAE indicate better prediction accuracy and smaller errors. Higher R2 signifies a better fit of the model to the data.\n",
        "\n",
        "The business impact of a machine learning model depends on its ability to accurately predict outcomes. A model with lower errors and higher R2 can lead to improved forecasting, enhanced decision-making, cost savings, and a competitive advantage. Ultimately, the model's performance on these metrics determines its usefulness in driving positive business impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "L2=Ridge()\n",
        "# Fit the Algorithm\n",
        "L2.fit(X_train,Y_train)\n",
        "# Predict on the model\n",
        "Y_pred_L2=L2.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "ridge_score=evaluate_model(L2,X_train,Y_train,Y_test,Y_pred_L2)\n",
        "score['Ridge_score']=ridge_score\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "L2=Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(L2, parameters, scoring='r2', cv=5,return_train_score=True)\n",
        "#fitting model\n",
        "ridge_regressor.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHSPdKXUNOSd"
      },
      "outputs": [],
      "source": [
        "#getting optimum parameters\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" r2 score is: \", ridge_regressor.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyK8voKGNNvT"
      },
      "outputs": [],
      "source": [
        "# Initiate ridge with best alpha\n",
        "L2 = Ridge(alpha = ridge_regressor.best_params_['alpha'])\n",
        "\n",
        "#prediction for Ridge regression\n",
        "L2.fit(X_train,Y_train)\n",
        "\n",
        "# Predict on model\n",
        "Y_pred_L2 = L2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc_cJfDWNNj4"
      },
      "outputs": [],
      "source": [
        "ridge_score=evaluate_model(L2,X_train,Y_train,Y_test,Y_pred_L2)\n",
        "score['Ridge_tuned']=ridge_score\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "GridSearchCV is used for hyperparameter optimization. GridSearchCV is a popular technique for hyperparameter tuning that exhaustively searches over a specified parameter grid to find the best combination of hyperparameters for a given model.\n",
        "\n",
        "The reason for using GridSearchCV in this case could be to systematically explore the hyperparameter space of the LinearRegression model. By providing a parameter grid (param_grid), GridSearchCV will perform an exhaustive search over all possible combinations of hyperparameters specified in the grid. It evaluates each combination using cross-validation (cv=5) and selects the best combination based on the scoring metric (scoring='r2', in this case).\n",
        "\n",
        "GridSearchCV is a reliable technique that helps to fine-tune model performance by finding the best hyperparameter values. It provides a systematic and comprehensive approach to hyperparameter optimization and can be beneficial when there are a limited number of hyperparameters to tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "There are no significant improvements in the evaluation metric scores with the tuned versions of the models compared to their respective base models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "MSE (Mean Squared Error): Lower values of MSE indicate better model performance in terms of minimizing the average squared difference between predicted and actual values. In this case, the Linear Regression model and the Linear Regression tuned model have the same MSE, which suggests that the tuned model did not improve the MSE compared to the base model.\n",
        "\n",
        "RMSE (Root Mean Squared Error): RMSE is the square root of MSE and represents the average magnitude of prediction errors. Similar to MSE, the Linear Regression model and the Linear Regression tuned model have the same RMSE, indicating no improvement in prediction accuracy.\n",
        "\n",
        "MAE (Mean Absolute Error): Lower MAE values indicate better model performance in terms of minimizing the average absolute difference between predicted and actual values. In this case, both the Linear Regression model and the Linear Regression tuned model have the same MAE, suggesting no improvement with tuning.\n",
        "\n",
        "R2 Score (R-squared): R2 score represents the proportion of variance explained by the model. Higher values of R2 indicate a better fit to the data. In this case, both the Linear Regression model and the Linear Regression tuned model have the same R2 score for both the training and testing sets, indicating no improvement in the model's ability to explain the variance.\n",
        "\n",
        "Based on these evaluation metric scores, it appears that the tuned models (Linear Regression tuned, Lasso Regression tuned, and Ridge tuned) did not show any improvement compared to their respective base models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Based on the evaluation metrics provided, the Linear Regression model would be chosen as the final prediction model. Here are the reasons for this choice:\n",
        "\n",
        "**Similar Performance:** The Linear Regression model and the Linear Regression tuned model have nearly identical performance across all evaluation metrics, including MSE, RMSE, MAE, R2 score, and Adjusted R2. Therefore, there is no significant improvement achieved by the tuning process.\n",
        "\n",
        "**Simplicity:** Linear Regression is a simple and interpretable model. It assumes a linear relationship between the independent variables and the target variable, which makes it easier to understand and interpret the impact of each feature on the target variable.\n",
        "\n",
        "**Efficiency:** Linear Regression is computationally efficient compared to more complex models, making it suitable for large datasets or situations where real-time predictions are required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "####The project successfully demonstrated the feasibility of using machine learning techniques to predict the sales of Rossman stores.The keys points are:\n",
        "  *   Higher sales on weekends (Sunday and Saturday) and lower sales on weekdays.\n",
        "  *   Storetype A is the most common, while storetype B is the least common.\n",
        "  *   State holidays have a negative impact on sales, while school holidays\n",
        "   have a positive impact.\n",
        "  *   Promotions drive higher sales and customer engagement.\n",
        "  *   Storetype \"b\" with assortment \"c\" generates the highest percentage of   sales.\n",
        "  *   Competition distance alone does not strongly predict sales.\n",
        "  *    Being open significantly boosts sales.\n",
        "  *   Linear regression model with regularization techniques, specifically\n",
        "      Lasso and Ridge regression, were employed to predict sales for Rossman stores.\n",
        "  *   The models were evaluated using metrics such as mean squared error (MSE),\n",
        "      root mean squared error (RMSE), mean absolute error (MAE), and R-squared (R2) score.\n",
        "  *   The selected model (Linear regression) can be considered\n",
        "      as the final prediction model based on its evaluation metrics and performance.\n",
        "\n"
      ]
    }
  ]
}